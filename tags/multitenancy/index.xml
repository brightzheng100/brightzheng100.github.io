<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Multitenancy on The future is Bright</title><link>https://brightzheng100.github.io/tags/multitenancy/</link><description>Recent content in Multitenancy on The future is Bright</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Copyright Â© 2021 Bright Zheg. All Rights Reserved.</copyright><lastBuildDate>Sat, 19 Aug 2023 22:01:46 +0800</lastBuildDate><atom:link href="https://brightzheng100.github.io/tags/multitenancy/index.xml" rel="self" type="application/rss+xml"/><item><title>Multi-tenancy Solutions for Kubernetes Series: Evaluation Criteria</title><link>https://brightzheng100.github.io/post/2023/08/multi-tenancy-solutions-for-kubernetes-series-evaluation-criteria/</link><pubDate>Sat, 19 Aug 2023 22:01:46 +0800</pubDate><guid>https://brightzheng100.github.io/post/2023/08/multi-tenancy-solutions-for-kubernetes-series-evaluation-criteria/</guid><description>
&lt;h2 id="overview">Overview&lt;/h2>
&lt;p>Kubernetes' official website has a good &lt;a href="https://kubernetes.io/docs/concepts/security/multi-tenancy/">explaination&lt;/a> about the motivation, use cases, considerations, and the potential patterns of implementing the multi-tenancy in Kubernetes.&lt;/p>
&lt;p>Running Kubernetes is costly in terms of the required resources and the overhead of managing the clusters.
And Kubernetes does not support multi-tenancy natively even it has some building blocks to support isolation for different teams and users.&lt;/p>
&lt;p>A real multi-tenancy solution is still desirable.&lt;/p>
&lt;p>Multi-tenancy in this context is about how to share a physical Kubernetes cluster to different tenants, with some sort of isolation and control. Some may even look at a broader landscape to build multi-tenancy solution across multiple clusters.&lt;/p>
&lt;p>There are many innovative solutions / open-source projects in the vibrant Kubernetes community.&lt;/p>
&lt;p>In this blog series, I'm going to discuss the potential evaluation criteria and dive into two very interesting projects, among others, to walk through the evaluation process:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://www.vcluster.com/docs/what-are-virtual-clusters">vcluster&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://capsule.clastix.io/docs/">Capsule&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>This blog series includes 4 parts:&lt;/p>
&lt;ul>
&lt;li>The evaluation criteria (this blog)&lt;/li>
&lt;li>The evaluation process for &lt;strong>vcluster&lt;/strong> (will add the link once it's ready)&lt;/li>
&lt;li>The evaluation process for &lt;strong>Capsule&lt;/strong> (will add the link once it's ready)&lt;/li>
&lt;li>The comparison and conclusion (will add the link once it's ready)&lt;/li>
&lt;/ul>
&lt;h2 id="evaluation-criteria">Evaluation Criteria&lt;/h2>
&lt;p>In general, there are two major sets of evaluating criteria:&lt;/p>
&lt;ul>
&lt;li>Control Plane Isolation&lt;/li>
&lt;li>Data Plane Isolation&lt;/li>
&lt;/ul>
&lt;p>Even the potential topics under these two major sets of evaluating criteria would not be exhaustive, but let's have a try and focus on some key areas.
I may add more evaluation criteria along the days, if that makes sense.&lt;/p>
&lt;p>I'm going to evaluate the criteria in a multi-node &lt;code>k3s&lt;/code> cluster, running on Docker (powered by Rancher Desktop), on my MacBook Pro.&lt;/p>
&lt;h3 id="control-plane-isolation">Control Plane Isolation&lt;/h3>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Topic&lt;/th>
&lt;th>Why it's important?&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>Authentication&lt;/td>
&lt;td>Each tenant may want to reuse their existing user management &amp;amp; authentication mechanism so it may become the starting point of integration with Kubernetes cluster(s)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Authorization with Role-Based Access Control (RBAC)&lt;/td>
&lt;td>Each tenant should have their needs of RBAC so that they can assign different teams for performing different tasks&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Resource Quotas&lt;/td>
&lt;td>Maintaining proper limitations/boundaries, like resource quotas, is very key in a multi-tenant env for necessary control and fairness&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Cluster-wide resources (e.g. CRD, ClusterRole/ClusterRoleBinding)&lt;/td>
&lt;td>Cluster-wide resources like CRDs are very common in Operator patterns for highly specialized software components and it may become a huge management challenge in a multi-tenant env&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="data-plane-isolation">Data Plane Isolation&lt;/h3>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Topic&lt;/th>
&lt;th>Why it's important?&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>Container Runtime&lt;/td>
&lt;td>Containers share the host kernel, which can lead to vulnerabilities and potential container breakouts or remote code execution. To mitigate these risks, each tenant may have their own preferences to run containers on different &amp;quot;Runtime Class&amp;quot;, especially when there are quite VM-like options like &lt;a href="https://katacontainers.io/">Kata Containers&lt;/a>.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Storage Isolation&lt;/td>
&lt;td>Storage can be a must-have feature when running stateful workloads in Kubernetes. Having tenant-managed StorageClass can offer the necessary power for tenants to work diversified workloads. Meanwhile, there is always a need to restrict the usage of some volumes like &lt;code>hostPath&lt;/code> to avoid the abuse of node-local storage.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Network Isolation&lt;/td>
&lt;td>Network isolation is typically achieved through NetworkPolicy, which restricts network flow between pods and reduces unexpected network access. Advanced network isolation can be achieved through service mesh implementations like Istio or Linkerd.&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="getting-ready">Getting Ready&lt;/h2>
&lt;p>Install &lt;code>k3d&lt;/code> CLI, and then use it to provision and simulate a multi-node Kubernetes Cluster.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">&lt;span class="line">&lt;span class="ln">1&lt;/span>&lt;span class="cl">wget -q -O - https://raw.githubusercontent.com/k3d-io/k3d/main/install.sh &lt;span class="p">|&lt;/span> bash
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="ln">2&lt;/span>&lt;span class="cl">k3d cluster create mycluster --agents &lt;span class="m">3&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>In just 1-2 minutes, depending on your download speed, you should be able to get a cluster like this, which has 1 Master Node and 3 Worker Nodes:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">&lt;span class="line">&lt;span class="ln">1&lt;/span>&lt;span class="cl">$ kubectl get nodes
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="ln">2&lt;/span>&lt;span class="cl">NAME STATUS ROLES AGE VERSION
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="ln">3&lt;/span>&lt;span class="cl">k3d-mycluster-server-0 Ready control-plane,master 17s v1.27.4+k3s1
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="ln">4&lt;/span>&lt;span class="cl">k3d-mycluster-agent-0 Ready &amp;lt;none&amp;gt; 13s v1.27.4+k3s1
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="ln">5&lt;/span>&lt;span class="cl">k3d-mycluster-agent-1 Ready &amp;lt;none&amp;gt; 14s v1.27.4+k3s1
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="ln">6&lt;/span>&lt;span class="cl">k3d-mycluster-agent-2 Ready &amp;lt;none&amp;gt; 12s v1.27.4+k3s1
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Okay, now we're ready to evaluate our solutions.&lt;/p>
&lt;p>I'll follow up accordingly and evaluate &lt;a href="https://www.vcluster.com/docs/what-are-virtual-clusters">vcluster&lt;/a> and &lt;a href="https://capsule.clastix.io/docs/">Capsule&lt;/a>, one by one.&lt;/p>
&lt;p>So stay tuned!&lt;/p></description></item></channel></rss>